{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw3p2_bootcamp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqxhejj_yxxo"
      },
      "source": [
        "# 1 Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPhXLOOGy23O"
      },
      "source": [
        "## 1.1 Google Drive - Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e15Pr4YZyzx6",
        "outputId": "a5f98d79-e20e-451d-cd70-a01237641ec0"
      },
      "source": [
        "# Google drive setup\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxC5bG9DzCwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac628b5-ea35-4b0f-96b9-430bdd13bde6"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hhAHy5S2lnF"
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"argajadeepakshende\",\"key\":\"5fab11c8416a4039725989fbef9ccbd2\"}\n",
        "with open('.kaggle/kaggle.json','w') as file: json.dump(token, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDAvSWLFzHTy"
      },
      "source": [
        "## 1.2 Kaggle Data Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWdExdMz2rQ-",
        "outputId": "0fece97d-e775-4a5c-869b-1a3b57854b22"
      },
      "source": [
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "!cp /content/.kaggle/kaggle.json /root/.kaggle/\n",
        "!kaggle config set -n path -v /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- path is now set to: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvgYuI692vS1",
        "outputId": "ff9579ba-b4c0-4d4d-be55-ab1b41b3500e"
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: kaggle 1.5.12\n",
            "Uninstalling kaggle-1.5.12:\n",
            "  Successfully uninstalled kaggle-1.5.12\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.3.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.3.1\n",
            "Collecting kaggle==1.5.6\n",
            "  Downloading kaggle-1.5.6.tar.gz (58 kB)\n",
            "     |████████████████████████████████| 58 kB 3.2 MB/s             \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (4.62.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle==1.5.6) (5.0.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle==1.5.6) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-py3-none-any.whl size=72857 sha256=1768180d57d61617d1d97a4b08965735093e1e03107367927a9cd13898e67cad\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/e7/e7/eb3c3d514c33294d77ddd5a856bdd58dc9c1fabbed59a02a2b\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhUzmdN9BMha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d1f82c5-a104-47e8-d5f9-eae4f46499db"
      },
      "source": [
        "# download data\n",
        "!kaggle competitions download -c 11785-fall2021-hw3p2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 11785-fall2021-hw3p2.zip to /content/competitions/11785-fall2021-hw3p2\n",
            "100% 2.34G/2.35G [00:12<00:00, 98.6MB/s]\n",
            "100% 2.35G/2.35G [00:12<00:00, 209MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lxbGtNvzP5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374bd4ff-8247-408a-8a9a-c558f16f9312"
      },
      "source": [
        "!unzip /content/competitions/11785-fall2021-hw3p2/11785-fall2021-hw3p2.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/competitions/11785-fall2021-hw3p2/11785-fall2021-hw3p2.zip\n",
            "  inflating: HW3P2_Data/dev.npy      \n",
            "  inflating: HW3P2_Data/dev_labels.npy  \n",
            "  inflating: HW3P2_Data/phoneme_list.py  \n",
            "  inflating: HW3P2_Data/sample_submission.csv  \n",
            "  inflating: HW3P2_Data/test.npy     \n",
            "  inflating: HW3P2_Data/train.npy    \n",
            "  inflating: HW3P2_Data/train_labels.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v4SIZkWz8xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "903cae93-3878-4f12-a7d7-bcbd4816d4e5"
      },
      "source": [
        "!ls HW3P2_Data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev_labels.npy\tphoneme_list.py        test.npy\t\t train.npy\n",
            "dev.npy\t\tsample_submission.csv  train_labels.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWjk6wdDKGM0"
      },
      "source": [
        "## 1.3 Library Installations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCW-7s2CKRE6"
      },
      "source": [
        "Install [ctcdecode](https://github.com/parlance/ctcdecode)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWnh9OW2KFC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889a4c60-336c-4230-eb69-375937af70d9"
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1102, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 1102 (delta 16), reused 28 (delta 13), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1102/1102), 780.91 KiB | 12.39 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 14051, done.        \n",
            "remote: Counting objects: 100% (364/364), done.        \n",
            "remote: Compressing objects: 100% (296/296), done.        \n",
            "remote: Total 14051 (delta 109), reused 120 (delta 55), pack-reused 13687        \n",
            "Receiving objects: 100% (14051/14051), 5.76 MiB | 14.49 MiB/s, done.\n",
            "Resolving deltas: 100% (7989/7989), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=8d2e4f04a82d6b46673a58b36f9af94abe72bc04e05b75f6d738cff7ad4846f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "/content/ctcdecode\n",
            "Processing /content/ctcdecode\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.3-cp37-cp37m-linux_x86_64.whl size=13295334 sha256=b13905962c5312000c4853e794ddd0bd0fd5d1e9aca4bc0a9c17fbcc78935bbc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zs8n4z01/wheels/da/bb/b4/233de9fd7927245208e27bcf688bf5680ae3f3874be2895eef\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFq2DZ1JKmx0"
      },
      "source": [
        "Install [levenshtein distance calculation library](https://github.com/ztane/python-Levenshtein) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wV1_xPiKiJV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec680ac9-2bec-419f-ab70-c3bfe4a6b5ef"
      },
      "source": [
        "!pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[?25l\r\r     |██████▌                         | 10 kB 35.8 MB/s eta 0:00:01\r     |█████████████                   | 20 kB 17.6 MB/s eta 0:00:01\r     |███████████████████▌            | 30 kB 15.2 MB/s eta 0:00:01\r     |██████████████████████████      | 40 kB 13.9 MB/s eta 0:00:01\r     |████████████████████████████████| 50 kB 3.2 MB/s             \n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (57.4.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149874 sha256=88207d60d988bfb68c9247b5edf50143782d2ba06448dff59ab8814a4c444633\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yqlnQRA0DZk"
      },
      "source": [
        "## 1.4 Libraries & Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAHPFFCc0C7b"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import Levenshtein as lev\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pdb\n",
        "import gc\n",
        "from tqdm.notebook import trange, tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvSpD3_q0UHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f8b3b9e-c130-4be6-b28c-5716176a2396"
      },
      "source": [
        "# Check if cuda is available and set device\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "num_workers = 8 if cuda else 0\n",
        "\n",
        "print(\"Cuda = \", str(cuda), \" with num_workers = \", str(num_workers),  \" system version = \", sys.version)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cuda =  True  with num_workers =  8  system version =  3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YopAeO_XRhTQ"
      },
      "source": [
        "# 2 Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKo7GEsBa4sR"
      },
      "source": [
        "## 2.1 Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BDZrzzlF5sq"
      },
      "source": [
        "# load training and dev data\n",
        "train_data = np.load('HW3P2_Data/train.npy', allow_pickle=True)\n",
        "train_labels = np.load('HW3P2_Data/train_labels.npy', allow_pickle=True)\n",
        "\n",
        "dev_data = np.load('HW3P2_Data/dev.npy', allow_pickle=True)\n",
        "dev_labels = np.load('HW3P2_Data/dev_labels.npy', allow_pickle=True)\n",
        "\n",
        "# load test data\n",
        "test_data = np.load('HW3P2_Data/test.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf89XpGrmYHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19cdb48-d4a1-4c6f-d69d-b6b39e5daf74"
      },
      "source": [
        "print(f'Train data: {train_data.shape}')\n",
        "print(f'Train labels {train_labels.shape}')\n",
        "\n",
        "print(f'Dev data: {dev_data.shape}')\n",
        "print(f'Dev labels {dev_labels.shape}')\n",
        "\n",
        "print(f'Test data: {test_data.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: (14542,)\n",
            "Train labels (14542,)\n",
            "Dev data: (2200,)\n",
            "Dev labels (2200,)\n",
            "Test data: (2561,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iLs7aLgbB8Q"
      },
      "source": [
        "## 2.2 Custom Dataset Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-0Seqh4Cp9F"
      },
      "source": [
        "# Define dataset class\n",
        "class MyDataSet(Dataset):\n",
        "  # load the dataset\n",
        "  def __init__(self, x, y):\n",
        "    self.X = x\n",
        "    self.Y = y\n",
        "\n",
        "  # get number of items/rows in dataset\n",
        "  def __len__(self):\n",
        "    return len(self.Y)\n",
        "\n",
        "  # get row item at some index\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.as_tensor(self.X[index], dtype=torch.float32)\n",
        "    y = torch.as_tensor(self.Y[index], dtype=torch.long)\n",
        "    \n",
        "    return x, y\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51ip7ahpulen"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    \n",
        "    input = []\n",
        "    target = []\n",
        "    for x in batch:\n",
        "      input.append(x[0])\n",
        "      target.append(x[1])\n",
        "    input_padded = pad_sequence(input, batch_first=True) \n",
        "    target_padded = pad_sequence(target, batch_first=True)\n",
        "    input_len = torch.as_tensor([len(x) for x in input],dtype=torch.long)\n",
        "    target_len = torch.as_tensor([len(x) for x in target],dtype=torch.long)\n",
        "    return input_padded, target_padded, input_len, target_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYTDtHEGHsWZ"
      },
      "source": [
        "# Define dataset class\n",
        "class TestDataSet(Dataset):\n",
        "  \n",
        "  def __init__(self, x):\n",
        "    self.X = x\n",
        "\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.X) \n",
        "\n",
        " \n",
        "  def __getitem__(self, index):\n",
        "    x = torch.as_tensor(self.X[index], dtype=torch.float32)\n",
        "    return x,torch.as_tensor(np.array([-1]), dtype=torch.long)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4ppavAxbGYv"
      },
      "source": [
        "## 2.3 Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_knptYW7RR73"
      },
      "source": [
        "batch_size = 32 # TODO: decide on batch size\n",
        "\n",
        "# training data\n",
        "train = MyDataSet(train_data, train_labels)\n",
        "#train_args = .... # TODO: remember to use collate_fn\n",
        "train_loader = DataLoader(train, shuffle=True, batch_size=batch_size, num_workers=8, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "# validation data\n",
        "dev = MyDataSet(dev_data, dev_labels)\n",
        "#dev_args = .... # TODO: remember to use collate_fn\n",
        "dev_loader = DataLoader(dev, shuffle=True, batch_size=batch_size, num_workers=8, collate_fn=collate_fn, pin_memory=True)\n",
        "\n",
        "# test data\n",
        "test = TestDataSet(test_data)\n",
        "#test_args = .... # TODO: remember to use collate_fn\n",
        "test_loader = DataLoader(test, shuffle=False, batch_size=batch_size, num_workers=8, collate_fn=collate_fn, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5SRjrPSzpIn",
        "outputId": "40fc7757-1aff-4d04-e479-82866eefea29"
      },
      "source": [
        "train_data[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1504, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt_fIhfDbMMm"
      },
      "source": [
        "# 2 Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSSX7kU5XBy_"
      },
      "source": [
        "## 2.1 Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-sSvKi9TR_M"
      },
      "source": [
        "# TODO: Create model    \n",
        "class LSTMModel(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
        "    super(LSTMModel, self).__init__()\n",
        "    self.cnn = torch.nn.Sequential(\n",
        "            nn.Conv1d(input_size, hidden_size, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm1d(hidden_size),\n",
        "            nn.ReLU(inplace=True))\n",
        "    self.lstm = nn.LSTM(input_size=hidden_size,\n",
        "                            hidden_size=hidden_size,\n",
        "                            num_layers=4,\n",
        "                            bias=True,\n",
        "                            batch_first=True,\n",
        "                            dropout=0.2, \n",
        "                            bidirectional=True)   \n",
        "   \n",
        "    \n",
        "    self.linear = torch.nn.Sequential(\n",
        "            nn.Linear(hidden_size*2, hidden_size),\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.Linear(hidden_size, output_size))\n",
        "\n",
        "    \n",
        "  def forward(self, x, lengths): \n",
        "    x_cnn_in = x.permute(0, 2, 1) \n",
        "    x_lstm_in = self.cnn(x_cnn_in).permute(2, 0, 1) \n",
        "    x_packed_input = pack_padded_sequence(x_lstm_in, lengths, enforce_sorted=False)\n",
        "    x_packed_out, hidden = self.lstm(x_packed_input)        \n",
        "    x_out, out_len = pad_packed_sequence(x_packed_out, batch_first=True)       \n",
        "   \n",
        "    output = self.linear(x_out)\n",
        "    output = output.log_softmax(2)   \n",
        "    output = output.permute(1, 0, 2)\n",
        "    \n",
        "    return output, out_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_2OrOTObTEy"
      },
      "source": [
        "## 2.2 Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q8xJFgnZT1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee462e05-631d-41b5-df56-b1eb2414c4fa"
      },
      "source": [
        "# create model\n",
        "input_size = 40\n",
        "hidden_size = 512\n",
        "num_layers = 4\n",
        "output_size = 42\n",
        "\n",
        "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
        "model = model.to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTMModel(\n",
            "  (cnn): Sequential(\n",
            "    (0): Conv1d(40, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
            "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (lstm): LSTM(512, 512, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "  (linear): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (2): Linear(in_features=512, out_features=42, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1hBJnqPjxyu"
      },
      "source": [
        "# 4 Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azt5PaudbbmK"
      },
      "source": [
        "## 4.0 Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6cbZIpDBWFa"
      },
      "source": [
        "# Hyperparams\n",
        "criterion = nn.CTCLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-3 , weight_decay=5e-6)\n",
        "    \n",
        "# You can add a LR scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWLIH1eNbjtg"
      },
      "source": [
        "## 4.1 Train Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtUS0ck-aC5-"
      },
      "source": [
        "# Train the model\n",
        "def train(model, train_loader, criterion, optimizer,epoch):\n",
        "  model.train()\n",
        "\n",
        "  avg_loss = 0.0\n",
        "  start = time.time()\n",
        "\n",
        "  for batch_idx, (data, target, data_len, target_len) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        data = data.cuda() \n",
        "        target = target.cuda()\n",
        "        data_len = data_len.cuda()\n",
        "        target_len = target_len.cuda()\n",
        "\n",
        "        output, out_data_len = model(data, data_len) \n",
        "        avg_loss = criterion(output, \n",
        "                         target, \n",
        "                         out_data_len, \n",
        "                         target_len) \n",
        "        avg_loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 50 == 0:\n",
        "            print(\"Epoch: {}\\tBatch: {}\\tTimestamp: {}\".format(epoch, batch_idx, time.time() - start))\n",
        "        \n",
        "  end = time.time()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idmvOyiEq63H"
      },
      "source": [
        "## 4.2 CTC Decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrIW7OENr7fg"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"HW3P2_Data\")\n",
        "\n",
        "from phoneme_list import PHONEME_MAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mby2lwGsX-a"
      },
      "source": [
        "from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "\n",
        "def decode(output_prob, data_len, beamWidth):\n",
        "    decoder = CTCBeamDecoder(labels=PHONEME_MAP, beam_width=1,\n",
        "                            num_processes=os.cpu_count(), log_probs_input=True)\n",
        "    output_prob = torch.permute(output_prob, (1,0,2)) \n",
        "    output, beam_scores, timesteps, out_seq_len = decoder.decode(output_prob, data_len) \n",
        "    decoded = []\n",
        "    batch_size = output_prob.shape[0]\n",
        "    for b in range(batch_size):\n",
        "        decode = \"\".join([PHONEME_MAP[i] for i in output[b, 0, :out_seq_len[b][0]]])\n",
        "        decoded.append(decode)      \n",
        "        \n",
        "    return decoded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k4IeRESBsJT"
      },
      "source": [
        "def to_string(target):\n",
        "    return \"\".join([PHONEME_MAP[x] for x in target])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arxNVRFvj0ro"
      },
      "source": [
        "## 4.3 Validate Epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwivZLnvuILh"
      },
      "source": [
        "def test(model, data_loader, epoch):\n",
        "    model.eval()\n",
        "    start_time = time.time()\n",
        "    running_loss = 0.0\n",
        "    running_dist = 0.0\n",
        "    for batch_idx, (data, target, data_len, target_len) in enumerate(data_loader):\n",
        "      data = data.cuda()\n",
        "      target = target.cuda()\n",
        "      data_len = data_len.cuda()\n",
        "      target_len = target_len.cuda()\n",
        "      optimizer.zero_grad()   \n",
        "      output, out_data_len = model(data, data_len)\n",
        "      loss = criterion(output,target,\n",
        "                             out_data_len,\n",
        "                             target_len)\n",
        "            \n",
        "      running_loss = running_loss + loss.item()\n",
        "      decoded_string = decode(output, data_len, 1)\n",
        "      target_string = []\n",
        "      for i in target:\n",
        "        target_string.append(to_string(i))\n",
        "      for i in range(len(target_string)):\n",
        "        dist = lev.distance(decoded_string[i].replace(\" \", \"\"), target_string[i].replace(\" \", \"\"))                    \n",
        "        running_dist += dist\n",
        "        running_dist /= (i+1)    \n",
        "        if batch_idx % 50 == 0:\n",
        "          print(\"Epoch: {}\\tBatch: {}\\tTimestamp: {}\".format(epoch, batch_idx, time.time() - start_time))\n",
        "            \n",
        "            \n",
        "      loss_per_sample = running_loss / len(data_loader)\n",
        "        \n",
        "      return loss_per_sample, running_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8vCpkiblZbY"
      },
      "source": [
        "## 4.4 Run Epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvD2JK1ifND_"
      },
      "source": [
        "# 5 Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1MvZuK2b4TO"
      },
      "source": [
        "## 5.1 Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8ex0PLmuOVI"
      },
      "source": [
        "def predict(model, data_loader):\n",
        "    model.eval()\n",
        "    prediction = []\n",
        "    prediction = np.asarray(prediction)   \n",
        "    for batch_idx, (data, target, data_len, target_len) in enumerate(data_loader):\n",
        "        data = data.cuda()\n",
        "        target = target.cuda()\n",
        "        data_len = data_len.cuda()\n",
        "        target_len = target_len.cuda()\n",
        "        output, out_data_len = model(data, data_len)        \n",
        "        decoded_string = decode(output, data_len, 50)\n",
        "        prediction = np.append(prediction, decoded_string)     \n",
        "        \n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxRRHCZUepas"
      },
      "source": [
        "for i in range(26):\n",
        "  \n",
        "  print(\"Epoch: {}\".format(i))\n",
        "  train(model, train_loader, criterion, optimizer, i)\n",
        "  train_loss, train_dist = test(model, train_loader, i)\n",
        "  print('Train_Loss: {:.4f}\\tTrain_Dist: {:.4f}'.format(\n",
        "         train_loss, train_dist))\n",
        "  dev_loss, dev_dist = test(model, dev_loader, i)\n",
        "  print('Dev_Loss: {:.4f}\\tDev_Dist: {:.4f}'.format(\n",
        "            dev_loss, dev_dist))\n",
        "  scheduler.step(dev_loss)\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YD-iaHKSlUU"
      },
      "source": [
        "for i in range(2): \n",
        "  \n",
        "  print(\"Epoch: {}\".format(i))\n",
        "  train(model, train_loader, criterion, optimizer, i)\n",
        "  train_loss, train_dist = test(model, train_loader, i)\n",
        "  print('Train_Loss: {:.4f}\\tTrain_Dist: {:.4f}'.format(\n",
        "         train_loss, train_dist))\n",
        "  dev_loss, dev_dist = test(model, dev_loader, i)\n",
        "  print('Dev_Loss: {:.4f}\\tDev_Dist: {:.4f}'.format(\n",
        "            dev_loss, dev_dist))\n",
        "\n",
        "  scheduler.step(dev_loss)\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9FCkcb0eZUf"
      },
      "source": [
        "\n",
        "for i in range(7):\n",
        " \n",
        "  print(\"Epoch: {}\".format(i))\n",
        "  train(model, train_loader, criterion, optimizer, i)\n",
        "  train_loss, train_dist = test(model, train_loader, i)\n",
        "  print('Train_Loss: {:.4f}\\nTrain_Dist: {:.4f}'.format(\n",
        "         train_loss, train_dist))\n",
        "  dev_loss, dev_dist = test(model, dev_loader, i)\n",
        "  print('Dev_Loss: {:.4f}\\nDev_Dist: {:.4f}'.format(\n",
        "            dev_loss, dev_dist))\n",
        "\n",
        "  scheduler.step(dev_loss)\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaiCGH3K3Soj"
      },
      "source": [
        "model = torch.load('model_new.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHD-dFnF3WJh"
      },
      "source": [
        "# Hyperparams\n",
        "\n",
        "\n",
        "criterion = nn.CTCLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=2.5e-4 , weight_decay=5e-6)\n",
        "    \n",
        "# You can add a LR scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1, verbose=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USvwu88c3hah"
      },
      "source": [
        "for i in range(1):\n",
        "  \n",
        "  print(\"Epoch: {}\".format(i))\n",
        "  train(model, train_loader, criterion, optimizer, i)\n",
        "  train_loss, train_dist = test(model, train_loader, i)\n",
        "  print('Train_Loss: {:.4f}\\nTrain_Dist: {:.4f}'.format(\n",
        "         train_loss, train_dist))\n",
        "  dev_loss, dev_dist = test(model, dev_loader, i)\n",
        "  print('Dev_Loss: {:.4f}\\nDev_Dist: {:.4f}'.format(\n",
        "            dev_loss, dev_dist))\n",
        "\n",
        "  scheduler.step(dev_loss)\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxHiMEEpDJCK"
      },
      "source": [
        "torch.save(model,'model_new.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCvC54-3et04"
      },
      "source": [
        "pred = predict(model, test_loader)\n",
        "ids = np.array(range(len(pred)))\n",
        "df = pd.DataFrame({\"id\" : ids, \"Label\" : pred})\n",
        "df.to_csv(\"prediction.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I9VwH_ppG3b"
      },
      "source": [
        "## 5.2 Save Predictions to csv File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShgVcbGtiSNQ"
      },
      "source": [
        "## 5.3 Submit Predictions"
      ]
    }
  ]
}